{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc59291-04fb-4433-9a26-a47733cae51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba26fb-361a-4abd-93dd-ed606d6db482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple example demonstrating Multinomial HMM\n",
    "----------------------------------------------\n",
    "\n",
    "The Multinomial HMM is a generalization of the categorical HMM, with some key\n",
    "differences:\n",
    "\n",
    "- a categorical__ (or generalized Bernoulli/multinoulli) distribution models an\n",
    "  outcome of a die with `n_features` possible values, i.e. it is a\n",
    "  generalization of the Bernoulli distribution where there are ``n_features``\n",
    "  categories instead of the binary success/failure outcome; a categorical HMM\n",
    "  has the emission probabilities for each component parametrized by categorical\n",
    "  distributions.\n",
    "\n",
    "- a Multinomial__ distribution models the outcome of ``n_trials`` independent\n",
    "  rolls of die, each with ``n_features`` possible values; i.e.\n",
    "\n",
    "  - when ``n_trials = 1`` and ``n_features = 1``, it is a Bernoulli\n",
    "    distribution,\n",
    "  - when ``n_trials > 1`` and ``n_features = 2``, it is a Binomial\n",
    "    distribution,\n",
    "  - when ``n_trials = 1`` and ``n_features > 2``, it is a categorical\n",
    "    distribution.\n",
    "\n",
    "The emission probabilities for each component of a Multinomial HMM are\n",
    "parameterized by Multinomial distributions.\n",
    "\n",
    "__ https://en.wikipedia.org/wiki/categorical_distribution\n",
    "__ https://en.wikipedia.org/wiki/Multinomial_distribution\n",
    "\n",
    "\n",
    "1. states, n_components - [ release ,  pickup ]\n",
    "2. start probs    - [<release>, <pickup>]\n",
    "3. emission probs - what vocabulary word belongs to each state\n",
    "4. trans mat      - stay in a state or transition to other\n",
    "5. vocabulary     - words, n_features\n",
    "6. observations   - n_trials = 5 words is one sentence - observation, n_iter observations\n",
    "7. model setup    - n_trials, n_iter, n_features, n_components\n",
    "8. fit            - observations\n",
    "    - received - state for every sentence\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88f3faa6-5388-478f-a5b7-4f5004402206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac7a02cf-cd00-40e5-9c7c-3bc7a11f4517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics discussed:\n",
      "['release', 'release', 'release', 'release', 'pickup', 'pickup', 'pickup', 'release', 'release', 'pickup', 'pickup', 'release', 'release', 'release', 'release', 'release', 'release', 'pickup', 'pickup', 'pickup', 'release', 'release', 'pickup', 'pickup', 'release', 'release', 'release', 'release', 'release', 'release', 'pickup', 'pickup', 'pickup', 'release', 'release', 'pickup', 'pickup', 'release', 'release', 'release', 'release', 'release', 'release', 'pickup', 'pickup', 'pickup', 'release', 'release', 'pickup', 'pickup', 'release', 'release', 'release', 'release', 'release', 'release', 'pickup', 'pickup', 'pickup', 'release', 'release', 'pickup', 'pickup', 'release', 'release']\n",
      "Learned emission probs:\n",
      "[[0.25 0.01 0.49 0.25]\n",
      " [0.19 0.62 0.07 0.12]]\n",
      "Learned transition matrix:\n",
      "[[0.72 0.28]\n",
      " [0.42 0.58]]\n",
      "\n",
      "New Model\n",
      "Topics discussed:\n",
      "['pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup', 'release', 'pickup']\n",
      "Learned emission probs:\n",
      "[[0.13 0.27 0.27 0.33]\n",
      " [0.31 0.2  0.4  0.09]]\n",
      "Learned transition matrix:\n",
      "[[0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# For this example, we will model the stages of a conversation,\n",
    "# where each sentence is \"generated\" with an underlying topic, \"pickup\" or \"release\"\n",
    "states = [\"release\", \"pickup\"]\n",
    "id2topic = dict(zip(range(len(states)), states))\n",
    "# we are more likely to talk about pickups first\n",
    "start_probs = np.array([0.6, 0.4])\n",
    "\n",
    "# For each topic, the probability of saying certain words can be modeled by\n",
    "# a distribution over vocabulary associated with the categories\n",
    "\n",
    "vocabulary = [\"point\", \"grab\", \"five\", \"thumbsup\"]\n",
    "# if the topic is \"pickup\", we are more likely to talk about \"five\"\n",
    "# if the topic is \"release\", we are more likely to talk about \"grab\"\n",
    "emission_probs = np.array([[0.25, 0.1, 0.4, 0.25],\n",
    "                           [0.2, 0.5, 0.1, 0.2]])\n",
    "\n",
    "# Also assume it's more likely to stay in a state than transition to the other\n",
    "trans_mat = np.array([[0.8, 0.2], [0.2, 0.8]])\n",
    "\n",
    "\n",
    "# Pretend that every sentence we speak only has a total of 5 words,\n",
    "# i.e. we independently utter a word from the vocabulary 5 times per sentence\n",
    "# we observe the following bag of words (BoW) for 8 sentences:\n",
    "observations = [[\"point\", \"five\", \"five\", \"thumbsup\", \"five\"],\n",
    "        [\"thumbsup\", \"five\", \"five\", \"thumbsup\", \"five\"],\n",
    "        [\"point\", \"five\", \"five\", \"point\", \"five\"],\n",
    "        [\"thumbsup\", \"five\", \"thumbsup\", \"thumbsup\", \"point\"],\n",
    "        [\"point\", \"grab\", \"five\", \"thumbsup\", \"point\"],\n",
    "        [\"point\", \"grab\", \"grab\", \"thumbsup\", \"grab\"],\n",
    "        [\"grab\", \"grab\", \"grab\", \"thumbsup\", \"point\"],\n",
    "        [\"thumbsup\", \"five\", \"thumbsup\", \"thumbsup\", \"point\"],\n",
    "        [\"point\", \"five\", \"five\", \"point\", \"five\"],\n",
    "        [\"grab\", \"grab\", \"grab\", \"grab\", \"grab\"],\n",
    "        [\"five\", \"grab\", \"grab\", \"grab\", \"point\"],\n",
    "        [\"five\", \"five\", \"point\", \"five\", \"thumbsup\"],\n",
    "        [\"five\", \"five\", \"point\", \"five\", \"point\"] ]\n",
    "\n",
    "# Convert \"sentences\" to numbers:\n",
    "vocab2id = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "def sentence2counts(sentence):\n",
    "    ans = []\n",
    "    for word, idx in vocab2id.items():\n",
    "        count = sentence.count(word)\n",
    "        ans.append(count)\n",
    "    return ans\n",
    "\n",
    "X = []\n",
    "for sentence in observations:\n",
    "    row = sentence2counts(sentence)\n",
    "    X.append(row)\n",
    "\n",
    "data = np.array(X, dtype=int)\n",
    "\n",
    "# pretend this is repeated, so we have more data to learn from:\n",
    "lengths = [len(X)]*5\n",
    "sequences = np.tile(data, (5,1))\n",
    "\n",
    "\n",
    "# Set up model:\n",
    "model = hmm.MultinomialHMM(n_components=len(states),\n",
    "        n_trials=len(observations[0]),\n",
    "        n_iter=56,\n",
    "        init_params='')\n",
    "\n",
    "model.n_features = len(vocabulary)\n",
    "model.startprob_ = start_probs\n",
    "model.transmat_ = trans_mat\n",
    "model.emissionprob_ = emission_probs\n",
    "model.fit(sequences, lengths)\n",
    "logprob, received = model.decode(sequences)\n",
    "\n",
    "len(received)\n",
    "\n",
    "print(\"Topics discussed:\")\n",
    "print([id2topic[x] for x in received])\n",
    "\n",
    "print(\"Learned emission probs:\")\n",
    "print(np.round(model.emissionprob_,2))\n",
    "\n",
    "print(\"Learned transition matrix:\")\n",
    "print(np.round(model.transmat_,2))\n",
    "\n",
    "# Try to reset and refit:\n",
    "new_model = hmm.MultinomialHMM(n_components=len(states),\n",
    "        n_trials=len(observations[0]),\n",
    "        n_iter=55, init_params='ste')\n",
    "\n",
    "new_model.fit(sequences, lengths)\n",
    "logprob, received = new_model.decode(sequences)\n",
    "\n",
    "print(\"\\nNew Model\")\n",
    "print(\"Topics discussed:\")\n",
    "print([id2topic[x] for x in received])\n",
    "\n",
    "print(\"Learned emission probs:\")\n",
    "print(np.round(new_model.emissionprob_,2))\n",
    "\n",
    "print(\"Learned transition matrix:\")\n",
    "print(np.round(new_model.transmat_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab02daee-dbf0-46f4-9438-44cde60c0260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10, 10, 10, 10]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52777c98-96e1-414b-ab96-75aa4e5a06fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8795b320-95c7-4834-9e6c-ced3ac91448e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555beb51-801c-4c31-83af-9aca742b205b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dcd00-4ee0-40af-8262-67fe830d7426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6cc34e1-006c-4a58-a5f1-d23113644a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from srcmodules.Scenes import Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921b0b3b-a17a-473d-a6d6-86fd9ef99437",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'D4_1'\n",
    "train_samples = 4000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b67a8785-2a2e-4b0a-81e5-987845a31175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset \n",
    "data = np.load(f\"{os.path.expanduser('./datasets')}/{dataset_name}.npy\", allow_pickle=True)\n",
    "config = data.item()['config']\n",
    "A = config['A']\n",
    "G = config['G']\n",
    "lenG = config['lenG']\n",
    "lenA = config['lenA']\n",
    "Otypes = config['Otypes']\n",
    "lenOtypes = config['lenOtypes']\n",
    "CM = config['CM']\n",
    "dataset = data.item()['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ba19353-6e45-4ae8-987e-ad15e71a441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs_in = lenG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc5130f8-e5d9-4ae2-8833-54d73c833e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y(dataset):\n",
    "    X = np.zeros([len(dataset),len(dataset[0][2])])\n",
    "    Y = np.zeros((len(dataset)), dtype=tuple)\n",
    "    for n,sample in enumerate(dataset):\n",
    "        s = Scene(init='from_dict', import_data=sample[0])\n",
    "\n",
    "        X[n] = sample[2]\n",
    "        Y[n] = A.index(sample[1][0])\n",
    "    return X, Y\n",
    "\n",
    "X,Y = get_X_Y(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39d87426-578d-4879-8529-e5745bac5a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "409677dc-a848-417e-86b8-ea06c1d81735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_obs_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a44a074e-2cb1-4f1d-a2a3-43af529003c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 8, ..., 3, 1, 8], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b11f63-52a1-4111-95d9-df8a2a84b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gestures:                up,left,dwn,rght,fiv,grab,thum,rota,poin\n",
    "CM3_1[0,0,:,:] = np.array([[1,  .0, .0,  .0,  0, .0,   .0,  .0,  .0], # move_up\n",
    "                          [.0,   1, .0,  .0, .0, .0,    0,   0,  .0], # move_left\n",
    "                          [.0,  .0,  1,  .0,  0, .0,   .0,   0,  .0], # move_down\n",
    "                          [.0,  .0, .0,   1,  0, .0,   .0,  .0,  .0], # move_right\n",
    "                          [.0,  .0, .0,  .0, .0, .0,   .0,  .0,  .0], # put\n",
    "                          [.0,  .0, .0,  .0, .0, .0,   .0,  .0,  .0], # put_on\n",
    "                          [.0,  .0, .0,  .0, .0, .0,    0,   1,  .0], # pour\n",
    "                          [ 0,  .0, .0,  .0, .0,  1,    0,  .0,  .0], # pick_up\n",
    "                          [.0,  .0, .0,  .0, .0, .0,    1,  .0,  .0], # place\n",
    "                          [.0,  .0, .0,  .0, .0, .0,   .0,  .0,  .0], # open\n",
    "                          [.0,  .0, .0,  .0, .0, .0,   .0,  .0,  .0]])# close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
